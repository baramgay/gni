import os
import warnings
import zipfile
from pathlib import Path

import streamlit as st
import requests

from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings

warnings.filterwarnings("ignore")


# =========================
# ì„¤ì •ê°’
# =========================
APP_TITLE = "ğŸ“š ê²½ë‚¨ì—°êµ¬ì› ê·œì •ì§‘ ì±—ë´‡"
APP_CAPTION = "ê·œì •ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”"

GDRIVE_FILE_ID = "1JaLtAm3Xyz2Ae70ucEL9UGven5EUBOBM"
ZIP_NAME = "faiss_db.zip"
EXTRACT_ROOT_DIRNAME = "faiss_db_extracted"
EMBEDDING_MODEL_NAME = "jhgan/ko-sroberta-multitask"

# Secretsì—ì„œ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸°
GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY", "")


# =========================
# ìœ í‹¸ í•¨ìˆ˜
# =========================
def has_faiss_files(p: Path) -> bool:
    return (p / "index.faiss").exists() and (p / "index.pkl").exists()


def find_faiss_dir(search_root: Path) -> Path:
    candidates = [p.parent for p in search_root.rglob("index.faiss")]
    if not candidates:
        raise FileNotFoundError("ì••ì¶• í•´ì œ í›„ index.faissë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    candidates.sort(key=lambda p: len(p.parts))
    real_dir = candidates[0]

    if not has_faiss_files(real_dir):
        raise FileNotFoundError(f"{real_dir}ì— index.faissëŠ” ìˆì§€ë§Œ index.pklì´ ì—†ìŠµë‹ˆë‹¤.")
    return real_dir


def download_from_gdrive(file_id: str, destination: Path):
    URL = "https://docs.google.com/uc?export=download"
    session = requests.Session()

    resp = session.get(URL, params={"id": file_id}, stream=True, timeout=120)
    resp.raise_for_status()

    token = None
    for k, v in resp.cookies.items():
        if k.startswith("download_warning"):
            token = v
            break

    if token:
        resp = session.get(URL, params={"id": file_id, "confirm": token}, stream=True, timeout=120)
        resp.raise_for_status()

    destination.parent.mkdir(parents=True, exist_ok=True)
    with open(destination, "wb") as f:
        for chunk in resp.iter_content(chunk_size=1024 * 1024):
            if chunk:
                f.write(chunk)


def generate_answer(question: str, context: str, chat_history: list = None) -> str:
    """
    chat_history: [{"role": "user", "content": "..."}, {"role": "assistant", "content": "..."}, ...]
    """
    
    # ëŒ€í™” ì´ë ¥ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ìµœê·¼ 4í„´ = 8ê°œ ë©”ì‹œì§€)
    history_text = ""
    if chat_history:
        for msg in chat_history[-8:]:  # ìµœê·¼ 4í„´(8ê°œ ë©”ì‹œì§€)ë§Œ ì‚¬ìš©
            role = "ì‚¬ìš©ì" if msg["role"] == "user" else "AI"
            history_text += f"{role}: {msg['content']}\n\n"
    
    prompt = f"""ë‹¹ì‹ ì€ ê²½ë‚¨ì—°êµ¬ì›ì˜ ê·œì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë…¼ë¦¬ì  ì¶”ë¡  ëŠ¥ë ¥ì„ ë°œíœ˜í•˜ì—¬ ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.

**í•µì‹¬ ë°°ê²½ ì§€ì‹:**
- ê²½ë‚¨ì—°êµ¬ì› ìœ„ì¹˜: ì°½ì›ì‹œ
- ê´€ë‚´ì¶œì¥: ì°½ì›ì‹œ ë‚´ë¶€
- ê´€ì™¸ì¶œì¥: ì°½ì›ì‹œ ì™¸ë¶€ (ë¶€ì‚°, ê¹€í•´, ì§„ì£¼, ì„œìš¸, ì œì£¼ë„ ë“± ì°½ì›ì´ ì•„ë‹Œ ëª¨ë“  ì§€ì—­)

**ë…¼ë¦¬ì  ì¶”ë¡  ê·œì¹™:**
1. ì§€ì—­ ë¶„ë¥˜ ì¶”ë¡ :
   - ì„œìš¸ = ì°½ì› ì•„ë‹˜ â†’ ê´€ì™¸ì¶œì¥
   - ì œì£¼ë„ = ì°½ì› ì•„ë‹˜ â†’ ê´€ì™¸ì¶œì¥
   - ë¶€ì‚° = ì°½ì› ì•„ë‹˜ â†’ ê´€ì™¸ì¶œì¥
   - ëª¨ë“  ë¹„ì°½ì› ì§€ì—­ = ê´€ì™¸ì¶œì¥

2. ê¸ˆì•¡ ì ìš© ì¶”ë¡ :
   - ê·œì •ì— "ì„œìš¸ ì´ì™¸ ì§€ì—­ 7ë§Œì›"ì´ ìˆë‹¤ë©´
   - ì œì£¼ë„ëŠ” "ì„œìš¸ ì´ì™¸ ì§€ì—­"ì— í¬í•¨ë¨ â†’ 7ë§Œì› ì ìš©
   - ë¶€ì‚°ë„ "ì„œìš¸ ì´ì™¸ ì§€ì—­"ì— í¬í•¨ë¨ â†’ 7ë§Œì› ì ìš©
   
3. ë“±ê¸‰ ì ìš© ì¶”ë¡ :
   - ê·œì •ì— ëª…ì‹œë˜ì§€ ì•Šì€ ì§€ì—­ì€ ê°€ì¥ ê°€ê¹Œìš´ ìœ ì‚¬ ë“±ê¸‰ ì ìš©
   - "êµ­ì™¸ë§Œ ë“±ê¸‰ í‘œì‹œ"ë¼ë©´ â†’ êµ­ë‚´ëŠ” ë³„ë„ ê¸°ì¤€ ì ìš©

**ì œê³µëœ ê·œì •:**
{context}

**ì´ì „ ëŒ€í™” ë‚´ì—­ (ìµœê·¼ 4í„´):**
{history_text if history_text else "(ì—†ìŒ)"}

**í˜„ì¬ ì§ˆë¬¸:** {question}

**ë‹µë³€ ì‘ì„± ì ˆì°¨:**
Step 1: ì´ì „ ëŒ€í™”ë¥¼ ì°¸ê³ í•˜ì—¬ ë§¥ë½ íŒŒì•… (ëŒ€ëª…ì‚¬ "ê·¸ê³³", "ê·¸ëŸ¼" ë“± í•´ì„)
Step 2: ì§ˆë¬¸ì—ì„œ ì–¸ê¸‰ëœ ì§€ì—­ì´ ì°½ì›ì¸ì§€ ì•„ë‹Œì§€ ë¨¼ì € íŒë‹¨
Step 3: ê´€ë‚´/ê´€ì™¸ ë¶„ë¥˜ í™•ì •
Step 4: í•´ë‹¹ ë¶„ë¥˜ì— ì ìš©ë˜ëŠ” ê·œì • ì°¾ê¸°
Step 5: ë…¼ë¦¬ì  ì¶”ë¡ ìœ¼ë¡œ êµ¬ì²´ì  ê¸ˆì•¡/ì¡°ê±´ ë„ì¶œ
Step 6: ëª…í™•í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€ ì‘ì„±

**ë‹µë³€ ê·œì¹™:**
1. ë…¼ë¦¬ì  ì¶”ë¡  ê³¼ì •ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•˜ë˜, "Step 1, Step 2" ê°™ì€ í‘œí˜„ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
2. ì´ì „ ëŒ€í™”ë¥¼ ì°¸ê³ í•˜ë˜, ë¶ˆí•„ìš”í•˜ê²Œ ë°˜ë³µ ì„¤ëª…í•˜ì§€ ë§ˆì„¸ìš”
3. êµ¬ì²´ì  ê¸ˆì•¡, ì¡°ê±´ì„ ë°˜ë“œì‹œ ëª…ì‹œ
4. í˜ì´ì§€ ë²ˆí˜¸ ì¸ìš©
5. í™•ì‹¤í•˜ì§€ ì•Šì€ ì¶”ì •ì€ "âš ï¸ ì›ê·œì§‘ ì¬í™•ì¸ í•„ìš”" í‘œì‹œ
6. ì¡´ëŒ“ë§ ì‚¬ìš©
7. ì™„ê²°ëœ ë‹µë³€

**ì¤‘ìš”: ì§€ë‚˜ì¹˜ê²Œ ë³´ìˆ˜ì ìœ¼ë¡œ ë‹µë³€í•˜ì§€ ë§ˆì„¸ìš”. ë…¼ë¦¬ì ìœ¼ë¡œ ëª…í™•í•˜ê²Œ ì¶”ë¡  ê°€ëŠ¥í•˜ë©´ ìì‹ ìˆê²Œ ë‹µë³€í•˜ì„¸ìš”.**

**ë‹µë³€:**"""

    url = (
        "https://generativelanguage.googleapis.com/v1/models/"
        f"gemini-2.5-flash:generateContent?key={GEMINI_API_KEY}"
    )

    data = {
        "contents": [{"parts": [{"text": prompt}]}],
        "generationConfig": {
            "temperature": 0.5,
            "maxOutputTokens": 8192,
            "topP": 0.95,
            "topK": 40,
        },
    }

    # ì¬ì‹œë„ ë¡œì§
    max_retries = 3
    for attempt in range(max_retries):
        try:
            r = requests.post(url, json=data, timeout=60)
            
            if r.status_code == 200:
                result = r.json()
                if "candidates" in result and result["candidates"]:
                    return result["candidates"][0]["content"]["parts"][0]["text"]
            
            if r.status_code == 503 and attempt < max_retries - 1:
                import time
                time.sleep((attempt + 1) * 2)
                continue
            
            return f"âš ï¸ Gemini API ì˜¤ë¥˜ (status={r.status_code}): ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            
        except Exception as e:
            if attempt < max_retries - 1:
                import time
                time.sleep(2)
                continue
            return f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    
    return "âš ï¸ ì„œë²„ê°€ í˜¼ì¡í•©ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."


# =========================
# Vector DB ì¤€ë¹„
# =========================
@st.cache_resource
def prepare_vectordb() -> str:
    base = Path(".").resolve()
    extract_root = base / EXTRACT_ROOT_DIRNAME
    zip_path = base / ZIP_NAME

    if extract_root.exists():
        try:
            real_dir = find_faiss_dir(extract_root)
            return str(real_dir)
        except Exception:
            pass

    st.info("ğŸ”„ ë°ì´í„°ë² ì´ìŠ¤ ë‹¤ìš´ë¡œë“œ ì¤‘... (ìµœì´ˆ 1íšŒ, 1~2ë¶„ ì†Œìš”)")

    download_from_gdrive(GDRIVE_FILE_ID, zip_path)

    if not zipfile.is_zipfile(zip_path):
        head = zip_path.read_bytes()[:300]
        raise RuntimeError(
            "ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ì´ ZIPì´ ì•„ë‹™ë‹ˆë‹¤.\n"
            "Drive ê³µìœ  ì„¤ì •ì´ 'ë§í¬ê°€ ìˆëŠ” ëª¨ë“  ì‚¬ìš©ì'ì¸ì§€ í™•ì¸í•˜ì„¸ìš”."
        )

    extract_root.mkdir(parents=True, exist_ok=True)
    with zipfile.ZipFile(zip_path, "r") as z:
        z.extractall(extract_root)

    try:
        zip_path.unlink()
    except Exception:
        pass

    real_dir = find_faiss_dir(extract_root)
    st.success("âœ… ì¤€ë¹„ ì™„ë£Œ!")
    return str(real_dir)


@st.cache_resource
def load_retriever(db_path: str):
    embeddings = HuggingFaceEmbeddings(
        model_name=EMBEDDING_MODEL_NAME,
        model_kwargs={"device": "cpu"},
        encode_kwargs={"normalize_embeddings": True},
    )

    vectorstore = FAISS.load_local(
        db_path,
        embeddings,
        allow_dangerous_deserialization=True,
    )

    return vectorstore.as_retriever(
        search_type="similarity",
        search_kwargs={"k": 20},
    )


# =========================
# Streamlit UI
# =========================
st.set_page_config(
    page_title="ê²½ë‚¨ì—°êµ¬ì› ê·œì •ì§‘ ì±—ë´‡",
    page_icon="ğŸ“š",
    layout="wide",
)

st.title(APP_TITLE)
st.caption(APP_CAPTION)

try:
    db_path = prepare_vectordb()
except Exception as e:
    st.error("ë‹¤ìš´ë¡œë“œ/ì´ˆê¸°í™” ì‹¤íŒ¨")
    st.exception(e)
    st.stop()

with st.spinner("ì´ˆê¸°í™” ì¤‘..."):
    try:
        retriever = load_retriever(db_path)
    except Exception as e:
        st.error("ì´ˆê¸°í™” ì‹¤íŒ¨")
        st.exception(e)
        st.stop()

if not GEMINI_API_KEY or not GEMINI_API_KEY.strip():
    st.error("GEMINI_API_KEYê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
    st.stop()

if "messages" not in st.session_state:
    st.session_state.messages = []

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

user_input = st.chat_input("ì§ˆë¬¸ ì…ë ¥ (ì˜ˆ: ì œì£¼ë„ ì¶œì¥ ìˆ™ë°•ë¹„ëŠ”?)")

if user_input:
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
            try:
                docs = retriever.invoke(user_input)

                context = "\n\n".join(
                    [
                        f"[í˜ì´ì§€ {doc.metadata.get('page', 'N/A')}]\n{doc.page_content}"
                        for doc in docs
                    ]
                )

                # ì´ì „ ëŒ€í™” ì´ë ¥ ì „ë‹¬ (í˜„ì¬ ì§ˆë¬¸ ì œì™¸, ìµœê·¼ 4í„´ê¹Œì§€)
                chat_history = st.session_state.messages[:-1]
                response = generate_answer(user_input, context, chat_history)
                
                st.markdown(response)

                with st.expander("ğŸ“„ ì°¸ê³  ê·œì •"):
                    for i, doc in enumerate(docs, 1):
                        st.markdown(f"**[{i}] í˜ì´ì§€ {doc.metadata.get('page', 'N/A')}**")
                        st.text((doc.page_content or "")[:400] + "...")

                st.session_state.messages.append({"role": "assistant", "content": response})

            except Exception as e:
                st.error("ì˜¤ë¥˜ ë°œìƒ")
                st.exception(e)

with st.sidebar:
    st.header("ğŸ“‹ ì‚¬ìš© ì•ˆë‚´")
    st.markdown(
        """
### ì§ˆë¬¸ ì˜ˆì‹œ
- ì œì£¼ë„ ì¶œì¥ ìˆ™ë°•ë¹„ëŠ”?
- ì„œìš¸ ì¶œì¥ ì‹œ ì¼ë¹„ëŠ”?
- ë¶€ì‚° ê´€ì™¸ì¶œì¥ ì‹ë¹„ëŠ”?
- ì—°ì°¨ ê·œì •ì€?

### ì •ë³´
- ì›ê·œì§‘: 2025.12.22
- AI: Gemini 2.5 Flash
- ëŒ€í™” ë§¥ë½: ìµœê·¼ 4í„´
- ë…¼ë¦¬ì  ì¶”ë¡  ê°•í™”
"""
    )

    if st.button("ğŸ”„ ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.rerun()
