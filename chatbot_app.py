import streamlit as st
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
import requests
import json
import warnings
import os
import zipfile
import gdown

warnings.filterwarnings('ignore')

# ë²¡í„° DB ìë™ ë‹¤ìš´ë¡œë“œ
@st.cache_resource
def download_vectordb():
    db_path = "./faiss_gyeongnam_rules"
    
    if os.path.exists(db_path):
        return db_path
    
    st.info("ğŸ”„ ë°ì´í„°ë² ì´ìŠ¤ ë‹¤ìš´ë¡œë“œ ì¤‘... (ìµœì´ˆ 1íšŒ, 1-2ë¶„ ì†Œìš”)")
    
    # ì—¬ê¸°ì— Google Drive ID ì…ë ¥
    gdrive_id = "1kePVG0mv_YL45DdgR0YPaQknpTWJetrV"  # ì˜ˆ: 1ABC123DEF456GHI789
    
    try:
        # Google Driveì—ì„œ ë‹¤ìš´ë¡œë“œ
        url = f"https://drive.google.com/uc?id={gdrive_id}"
        output = "faiss_db.zip"
        gdown.download(url, output, quiet=False)
        
        # ì••ì¶• í•´ì œ
        with zipfile.ZipFile(output, 'r') as zip_ref:
            zip_ref.extractall(".")
        
        os.remove(output)
        st.success("âœ… ì¤€ë¹„ ì™„ë£Œ!")
        return db_path
        
    except Exception as e:
        st.error(f"ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        st.stop()
        return None

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ê²½ë‚¨ì—°êµ¬ì› ê·œì •ì§‘ ì±—ë´‡",
    page_icon="ğŸ“š",
    layout="wide"
)

st.title("ğŸ“š ê²½ë‚¨ì—°êµ¬ì› ê·œì •ì§‘ ì±—ë´‡")
st.caption("ê·œì •ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”")

# ë²¡í„° DB ì¤€ë¹„
db_path = download_vectordb()

# Gemini API í‚¤
GEMINI_API_KEY = "AIzaSyBJcMn59KUl-937xdj00pXsEIHUpkeTTnA"

# ì±—ë´‡ ë¡œë“œ
@st.cache_resource
def load_chatbot():
    try:
        embeddings = HuggingFaceEmbeddings(
            model_name="jhgan/ko-sroberta-multitask",
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        
        vectorstore = FAISS.load_local(
            db_path,
            embeddings,
            allow_dangerous_deserialization=True
        )
        
        retriever = vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={"k": 10}
        )
        
        return retriever
        
    except Exception as e:
        st.error(f"ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None

with st.spinner("ì´ˆê¸°í™” ì¤‘..."):
    retriever = load_chatbot()

if retriever is None:
    st.error("ì´ˆê¸°í™” ì‹¤íŒ¨")
    st.stop()

# Gemini API í˜¸ì¶œ
def generate_answer(question, context):
    prompt = f"""ë‹¹ì‹ ì€ ê²½ë‚¨ì—°êµ¬ì›ì˜ ê·œì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**ë°°ê²½:**
- ê²½ë‚¨ì—°êµ¬ì›ì€ ì°½ì›ì‹œì— ìœ„ì¹˜
- ê´€ë‚´ì¶œì¥: ì°½ì›ì‹œ ë‚´
- ê´€ì™¸ì¶œì¥: ì°½ì›ì‹œ ì™¸ (ë¶€ì‚°, ê¹€í•´ ë“±)

**ê·œì •:**
{context}

**ì§ˆë¬¸:** {question}

**ì§€ì¹¨:**
1. ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€
2. êµ¬ì²´ì  ê¸ˆì•¡, ì¡°ê±´ ëª…ì‹œ
3. í˜ì´ì§€ ì¸ìš©
4. ì¶”ì • ë‚´ìš©ì€ "âš ï¸ ì›ê·œì§‘ ì¬í™•ì¸ í•„ìš”" í‘œì‹œ
5. ì¡´ëŒ“ë§ ì‚¬ìš©
6. ì™„ê²°ëœ ë‹µë³€

**ë‹µë³€:**"""
    
    try:
        url = f"https://generativelanguage.googleapis.com/v1/models/gemini-2.5-flash:generateContent?key={GEMINI_API_KEY}"
        
        data = {
            "contents": [{"parts": [{"text": prompt}]}],
            "generationConfig": {
                "temperature": 0.4,
                "maxOutputTokens": 8192,
            }
        }
        
        response = requests.post(url, json=data, timeout=60)
        
        if response.status_code == 200:
            result = response.json()
            if 'candidates' in result:
                return result['candidates'][0]['content']['parts'][0]['text']
        
        return "ì˜¤ë¥˜ ë°œìƒ"
        
    except Exception as e:
        return f"ì˜¤ë¥˜: {e}"

# ì„¸ì…˜ ìƒíƒœ
if "messages" not in st.session_state:
    st.session_state.messages = []

# ëŒ€í™” í‘œì‹œ
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ì‚¬ìš©ì ì…ë ¥
user_input = st.chat_input("ì§ˆë¬¸ ì…ë ¥ (ì˜ˆ: ë¶€ì‚° ì¶œì¥ë¹„ëŠ”?)")

if user_input:
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)
    
    with st.chat_message("assistant"):
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
            docs = retriever.invoke(user_input)
            context = "\n\n".join([
                f"[í˜ì´ì§€ {doc.metadata.get('page', 'N/A')}]\n{doc.page_content}" 
                for doc in docs
            ])
            
            response = generate_answer(user_input, context)
            st.markdown(response)
            
            with st.expander("ğŸ“„ ì°¸ê³  ê·œì •"):
                for i, doc in enumerate(docs, 1):
                    st.markdown(f"**[{i}] í˜ì´ì§€ {doc.metadata.get('page')}**")
                    st.text(doc.page_content[:400] + "...")
            
            st.session_state.messages.append({"role": "assistant", "content": response})

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("ğŸ“‹ ì‚¬ìš© ì•ˆë‚´")
    st.markdown("""
    ### ì§ˆë¬¸ ì˜ˆì‹œ
    - ë¶€ì‚° ì¶œì¥ ì‹œ ì—¬ë¹„ëŠ”?
    - ì—°ì°¨ ê·œì •ì€?
    - ê²½ì¡°ì‚¬ íœ´ê°€ëŠ”?
    
    ### ì •ë³´
    - ì›ê·œì§‘: 2025.12.22
    - AI: Gemini 2.5 Flash
    """)
    
    if st.button("ğŸ”„ ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.rerun()